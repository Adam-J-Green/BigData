{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4be9e7",
   "metadata": {},
   "source": [
    "# Data Retrieval \n",
    "This code file completes the data collection and storage process. Headlines and financial data are gathered from respective sources, processed into final forms and stored in the PostgreSQL database. \n",
    "\n",
    "*The database used in this work is locally hosted, usage of this file outside of the environment in which it was created will be unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded0768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install yfinance\n",
    "!pip install pyspark\n",
    "!pip install findspark\n",
    "!pip install dateparser\n",
    "!pip install vaderSentiment\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from pyspark.sql.functions import sum,max,min,mean,count\n",
    "import datetime as dt\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "import findspark\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from os.path import abspath\n",
    "\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "with open('cfg.yml') as f:\n",
    "    config = yaml.load(f, Loader = SafeLoader)\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder \\\n",
    "    .master(config['spark']['spark_master'])\\\n",
    "    .appName('gather')\\\n",
    "    .enableHiveSupport()\\\n",
    "    .config('spark.sql.warehouse.dir', warehouse_location)\\\n",
    "    .config(config['spark']['spark_jars'], config['spark']['spark_jars_path'])\\\n",
    "    .config('spark.cores.max', '2')\\\n",
    "    .config('spark.executor.cores', '2')\\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2f7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = config['postgres']['url']\n",
    "props = {\n",
    "    'user': config['postgres']['user'],\n",
    "    'password' : config['postgres']['user'],\n",
    "    'url': url,\n",
    "    'driver': config['postgres']['driver']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666056ff",
   "metadata": {},
   "source": [
    "# Retrieve Headlines for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ca7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve headlines from financial post\n",
    "headers = {'User-Agent':\n",
    "\t'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:108.0) Gecko/20100101 Firefox/108.0'}\n",
    "def gather_headlines(company_name, ticker):\n",
    "    headlines = []\n",
    "    dates = []\n",
    "    for i in range(10, 30000, 10):    # Running for-loop\n",
    "        info_url = \"https://financialpost.com/search/?search_text=\"+company_name +\"&date_range=-3650d&sort=asc&from=\"+str(i)\n",
    "        page = requests.get(info_url, headers = headers)\n",
    "        parser = bs(page.content, \"html.parser\" )\n",
    "        date = parser.body.find_all('div', attrs={'class': 'article-card__meta-bottom'})\n",
    "        for span in date:\n",
    "            dates.append(span.text.split(\"   \")[1])\n",
    "        headline = parser.body.find_all('h3', class_ = 'article-card__headline text-size--extra-large--sm-up')\n",
    "        for x in headline:\n",
    "            headlines.append(x.text)\n",
    "    dates = dates[:len(headlines)]\n",
    "    file = {'date' : dates, \"headline\" : headlines}\n",
    "    file = pd.DataFrame(file)\n",
    "    print(file.head())\n",
    "    file['ticker'] = ticker\n",
    "    return file\n",
    "\n",
    "#calculate sentiment scores for each headlines and append to dataset\n",
    "def analyze_sent(df):\n",
    "    analyze_obj = SentimentIntensityAnalyzer()\n",
    "    df['sentiment']=df['headline'].apply(lambda headline: analyze_obj.polarity_scores(str(headline))['compound'])\n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "def final_sentiment(df):\n",
    "    return df.withColumn(\"sent_score\", df.mean_sentiment*(df.headline_count**2)).drop('headline', 'headline_count', 'mean_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5b8a4",
   "metadata": {},
   "source": [
    "# Process Sentiment Scores and Write to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d5c77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date                                           headline\n",
      "0  April 10, 2013   Personal computer shipments shrink 14% in wor...\n",
      "1  April 11, 2013         What you need to know before markets open \n",
      "2  April 11, 2013   Microsoft's Windows 8 gets blame for worst PC...\n",
      "3  April 11, 2013   Microsoft falls after Goldman warns of PC los...\n",
      "4  April 11, 2013   Electronic Arts lays off employees at Montrea...\n",
      "            date                                           headline\n",
      "0  April 5, 2013   4.05.13: 'Flurry of disappointment' for Canad...\n",
      "1  April 5, 2013   Facebook Home Q&A with mobile engineering dir...\n",
      "2  April 6, 2013   Discontinued products that we still miss dearly \n",
      "3  April 8, 2013   How DIRTT has built a successful green manufa...\n",
      "4  April 8, 2013   Review: The HTC One is the most beautiful And...\n",
      "             date                                           headline\n",
      "0  April 22, 2013   Google chairman Schmidt explores future of In...\n",
      "1  April 22, 2013   Netflix shares surge as profit, U.S. streamin...\n",
      "2  April 22, 2013   Closing Bell: TSX closes modestly higher amid...\n",
      "3  April 23, 2013   4.23.13: Mark Carney, travelling light but ta...\n",
      "4  April 23, 2013   Netflix becomes S&P's top performer as it stu...\n",
      "            date                                           headline\n",
      "0   July 9, 2013         What you need to know before markets open \n",
      "1   July 9, 2013   Tesla rises to record high as stock heads for...\n",
      "2  July 13, 2013   13 expensive side projects keeping the bigges...\n",
      "3  July 16, 2013   Tesla CEO Elon Musk morphs from Tony Stark to...\n",
      "4  July 18, 2013   GM is so afraid of Tesla it has assembled a s...\n",
      "          date                                           headline\n",
      "0  May 1, 2013         Transforce ready to ride out energy slump \n",
      "1  May 6, 2013   How Al Gore amassed a $200-million fortune af...\n",
      "2  May 7, 2013      The 40 most undervalued stocks in the market \n",
      "3  May 7, 2013   Desire2Learn launches software that predicts ...\n",
      "4  May 9, 2013   Canadian TV producers DHX Media, Nelvana, OUT...\n",
      "23/03/30 14:01:26 WARN TaskSetManager: Stage 0 contains a task of very large size (1907 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date                                                           headline ticker\n",
      "0  2013-04-10      Personal computer shipments shrink 14% in worst-ever decline    MSFT\n",
      "1  2013-04-11                         What you need to know before markets open    MSFT\n",
      "2  2013-04-11   Microsoft's Windows 8 gets blame for worst PC decline on record    MSFT\n",
      "3  2013-04-11                  Microsoft falls after Goldman warns of PC losses    MSFT\n",
      "4  2013-04-11             Electronic Arts lays off employees at Montreal studio    MSFT\n",
      "23/03/30 14:01:29 WARN TaskSetManager: Stage 1 contains a task of very large size (1907 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cis6180/anaconda3/lib/python3.9/site-packages/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 14:01:29 WARN TaskSetManager: Stage 2 contains a task of very large size (1907 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---------+\n",
      "|      date|            headline|ticker|sentiment|\n",
      "+----------+--------------------+------+---------+\n",
      "|2013-04-10| Personal compute...|  MSFT|      0.0|\n",
      "|2013-04-11| What you need to...|  MSFT|      0.0|\n",
      "|2013-04-11| Microsoft's Wind...|  MSFT|  -0.7579|\n",
      "|2013-04-11| Microsoft falls ...|  MSFT|  -0.4767|\n",
      "|2013-04-11| Electronic Arts ...|  MSFT|      0.0|\n",
      "|2013-04-12| 4.12.13: BlackBe...|  MSFT|      0.0|\n",
      "|2013-04-12| Motocross Madnes...|  MSFT|  -0.4939|\n",
      "|2013-04-12| Who says account...|  MSFT|  -0.3182|\n",
      "|2013-04-15| 4.15.13: Gold an...|  MSFT|      0.0|\n",
      "|2013-04-15| Microsoft smartw...|  MSFT|      0.0|\n",
      "|2013-04-16| Facebook, Apple ...|  MSFT|      0.0|\n",
      "|2013-04-16| Facebook Home se...|  MSFT|      0.0|\n",
      "|2013-04-17| Buying defensive...|  MSFT|  -0.1531|\n",
      "|2013-04-17| 4.17.13: Stickin...|  MSFT|      0.0|\n",
      "|2013-04-17| TSX tumbles as g...|  MSFT|  -0.2023|\n",
      "|2013-04-17| The bull case fo...|  MSFT|   0.5216|\n",
      "|2013-04-17| Learning to use ...|  MSFT|      0.0|\n",
      "|2013-04-18| Private equity t...|  MSFT|      0.0|\n",
      "|2013-04-18| Microsoft CFO Kl...|  MSFT|   0.4019|\n",
      "|2013-04-19| What you need to...|  MSFT|      0.0|\n",
      "+----------+--------------------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/03/30 14:01:34 WARN TaskSetManager: Stage 3 contains a task of very large size (1907 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import dateparser\n",
    "ticker_list = ['MSFT','GOOG','NFLX','TSLA', 'AMZN']\n",
    "company_list = ['microsoft', 'google', 'netflix', 'tesla', 'amazon']\n",
    "\n",
    "\n",
    "def process_headlines(ticker_list, company_list):\n",
    "    dfs = []\n",
    "    for tick, company in zip(ticker_list, company_list):\n",
    "        data = gather_headlines(company, tick)\n",
    "        dfs.append(data)\n",
    "    full_df = pd.concat(dfs)\n",
    "    dates = []\n",
    "    for index, row in full_df.iterrows():\n",
    "        date = dateparser.parse(row['date'], date_formats = [\"%d-%m-%y\"])\n",
    "        dates.append(date.date())\n",
    "    full_df['date'] = dates\n",
    "    full_df = ps.from_pandas(full_df)\n",
    "    print(full_df.head())\n",
    "    full_df = analyze_sent(full_df)\n",
    "    full_df = full_df.to_spark()\n",
    "    full_df.show()\n",
    "    aggregated = full_df.groupBy('date', 'ticker').agg(count('headline').alias('headline_count'), mean('sentiment').alias(\"mean_sentiment\"))\n",
    "    final_news = final_sentiment(aggregated) \n",
    "    final_news.write.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/financials\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", \"sentiment\") \\\n",
    "        .option(\"user\", \"adam\").option(\"password\", \"green\").mode('append').save()\n",
    "\n",
    "process_headlines(ticker_list, company_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45615eee",
   "metadata": {},
   "source": [
    "# Retrieve, Process and Store Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efe59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financials(ticker, start):\n",
    "    time_delt = dt.timedelta(days = 150)\n",
    "    start_day = start - time_delt\n",
    "    data = yf.download(str(ticker), start_day)\n",
    "    data['ticker'] = ticker\n",
    "    data = data.reset_index()\n",
    "    data = data.rename(columns = {'Date':'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Adj Close': 'adj_close', 'Volume':'volume'})\n",
    "    print('success!')\n",
    "    return data\n",
    "                       \n",
    "                       \n",
    "def EWMA(data, ndays): \n",
    "    EMA = pd.Series(data['close'].ewm(span = ndays, min_periods = ndays - 1).mean(), \n",
    "                 name = 'EWMA_' + str(ndays)) \n",
    "    data = data.join(EMA) \n",
    "    return data\n",
    "\n",
    "def rsi(close, periods = 14):\n",
    "    \n",
    "    close_delta = close.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "\n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi\n",
    "\n",
    "def BBANDS(data, window):\n",
    "    MA = data.close.rolling(window).mean()\n",
    "    SD = data.close.rolling(window).std()\n",
    "    data['MiddleBand'] = MA\n",
    "    data['UpperBand'] = MA + (2 * SD) \n",
    "    data['LowerBand'] = MA - (2 * SD)\n",
    "    return data\n",
    "\n",
    "def prep_financials(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    #df.set_index('date')\n",
    "    df['target'] = (df['close'])\n",
    "    df['tenmda'] = df['close'].rolling(10).mean()\n",
    "    df['twentymda'] = df['close'].rolling(20).mean()\n",
    "    df['fiftymda'] = df['close'].rolling(50).mean()\n",
    "    df['hundredmda'] = df['close'].rolling(100).mean()\n",
    "    df = EWMA(df, 20)\n",
    "    df = EWMA(df, 50) \n",
    "    df = EWMA(df, 100)\n",
    "    df['rsi'] = rsi(df['close'])\n",
    "    df = BBANDS(df, 40)\n",
    "    df.dropna(inplace = True)\n",
    "    df.reset_index()\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_finance(ticker_list):\n",
    "    finance_dfs = []\n",
    "    for tick in ticker_list:\n",
    "        data = get_financials(tick, dt.date(2015,1, 1))\n",
    "        data = prep_financials(data)\n",
    "        finance_dfs.append(data)\n",
    "    final_finance = pd.concat(finance_dfs)\n",
    "    final_finance = spark.createDataFrame(final_finance)\n",
    "    final_finance.write.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/financials\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\").option(\"dbtable\", \"company_data\") \\\n",
    "        .option(\"user\", \"adam\").option(\"password\", \"green\").mode('append').save()\n",
    "    \n",
    "ticker_list = ['MSFT','GOOG','NFLX','AMZN', 'TSLA']\n",
    "process_finance(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e294d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
